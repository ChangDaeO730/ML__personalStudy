{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# svm \n",
    "* `LinearSVC(C = , loss = \"hinge\")`\n",
    "* `SGDClassifier(loss = \"hinge\", alpha = 1/(m*C))` - 온라인 학습 지원\n",
    "* `SVC(kernel = , C = )` - kernel기법 지원, 젤 느림\n",
    "> p차원 벡터 point들을 p-1차원의 결정경계 초평면으로 분리한다.<br/>\n",
    "데이터들을 분리하는 초평면들 중 해당 초평면과 가장 가까운 각 클레스 데이터 점들(support vector) 까지의<br/> 거리(margin)가 최대가 되도록 하는 최대마진 초평면을 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris[\"data\"][:, (2, 3)]\n",
    "y = (iris[\"target\"] == 2).astype(np.float64)\n",
    "\n",
    "svm_clf = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"linaer_svc\", LinearSVC(C = 1, loss = \"hinge\")),\n",
    "    # same with SVC(kernel = \"linear\", C = 1) (slower)\n",
    "])\n",
    "\n",
    "svm_clf.fit(X, y)\n",
    "svm_clf.predict([[5.5, 1.7]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# non linear svm classification\n",
    "- feature들을 고차원으로 변환\n",
    "- 커널트릭"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('poly_features', PolynomialFeatures(degree=3)),\n",
       "                ('scaler', StandardScaler()),\n",
       "                ('svm_clf', LinearSVC(C=10, loss='hinge'))])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "X, y = make_moons(n_samples = 100, noise = 0.15)\n",
    "polynomial_svm_clf = Pipeline([\n",
    "    (\"poly_features\", PolynomialFeatures(degree = 3)),   # 고차원 특성 추가\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"svm_clf\", LinearSVC(C = 10, loss = \"hinge\"))\n",
    "])\n",
    "polynomial_svm_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1]\n",
      " [2 3]\n",
      " [4 5]]\n",
      "[[  1.   0.   1.   0.   0.   1.   0.   0.   0.   1.]\n",
      " [  1.   2.   3.   4.   6.   9.   8.  12.  18.  27.]\n",
      " [  1.   4.   5.  16.  20.  25.  64.  80. 100. 125.]]\n"
     ]
    }
   ],
   "source": [
    "poly = PolynomialFeatures(3)\n",
    "X = np.arange(6).reshape(3, 2)\n",
    "print(X)\n",
    "X_trans = poly.fit_transform(X)\n",
    "print(X_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('svm_clf', SVC(C=5, coef0=1, kernel='poly'))])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "X, y = make_moons(n_samples = 100, noise = 0.15)\n",
    "poly_kernel_svm_clf = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"svm_clf\", SVC(kernel=\"poly\", degree=3, coef0=1, C=5)) # 3차 다항식 커널 사용\n",
    "    ])\n",
    "poly_kernel_svm_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "유사도 특성을 추가하여 데이터 고차원으로 변환\n",
    "- radial basis function\n",
    "<img src = \"https://github.com/changdaeoh/HandsOn_ML/blob/main/images/5_8.png?raw=true\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('svm_clf', SVC(C=0.001, gamma=5))])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly_kernel_svm_clf = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"svm_clf\", SVC(kernel=\"rbf\", gamma = 5, C = 0.001)) # RBF 커널\n",
    "        # gamma는 정규분포의 sigma의 역수와 같은 의미 \n",
    "        # 값이 작을수록 분포의 산포가 커지고 캆이 클수록 분포의 산포가 작아짐\n",
    "        # -> 분포의 산포는 각 샘플의 영향범위\n",
    "    ])\n",
    "poly_kernel_svm_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Regression\n",
    "loss function\n",
    "<img src = \"https://github.com/changdaeoh/HandsOn_ML/blob/main/images/5_svm_regressor_loss.png?raw=true\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.svm import SVR, LinearSVR\n",
    "\n",
    "# svm_reg = LinearSVR(epsion = 1.5)\n",
    "# svm_poly_reg = SVR(kernel=\"poly\", degree=2, C=100, epsilon=0.1, gamma=\"scale\")\n",
    "# - epsilon parameter로 허용 노이즈정도를 설정"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
