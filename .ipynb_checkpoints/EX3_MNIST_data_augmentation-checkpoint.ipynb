{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "plt.style.use('seaborn-darkgrid')\n",
    "\n",
    "\n",
    "from sklearn.datasets import fetch_openml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation _ Shifting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = fetch_openml('mnist_784', version = 1)\n",
    "\n",
    "X, y = mnist[\"data\"], mnist[\"target\"]\n",
    "y = y.astype(np.uint8)\n",
    "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold=sys.maxsize, linewidth = 200) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_shifter(data, direction = [2,4,6,8], stride = 1):\n",
    "    '''Desciption\n",
    "    * data : 3-d array inputs (n, 28, 28)\n",
    "    * direction : list of shifting direction\n",
    "    * stride : shifting size\n",
    "    \n",
    "    outputs = (data | all of shifting results)\n",
    "    '''\n",
    "    # single input processing\n",
    "    if len(data.shape) == 2:\n",
    "        data = data.reshape(1, 28, 28)\n",
    "    # single direction processing\n",
    "    if isinstance(direction, int):\n",
    "        direction = [direction]\n",
    "    \n",
    "    d2, d8, d4, d6 = None, None, None, None\n",
    "    \n",
    "    for d in direction:\n",
    "        # row-wise shifting\n",
    "        if d == 2:\n",
    "            d2 = np.concatenate((np.zeros((data.shape[0],stride,data.shape[2])),data[:,:-stride,:]), axis = 1)\n",
    "        if d == 8:\n",
    "            d8 = np.concatenate((data[:,stride:,:], np.zeros((data.shape[0],stride,data.shape[2]))), axis = 1)\n",
    "        # column-wise shifting\n",
    "        if d == 4:\n",
    "            d4 = np.concatenate((data[:,:,stride:], np.zeros((data.shape[0],data.shape[1],stride))), axis = 2)\n",
    "        if d == 6:\n",
    "            d6 = np.concatenate((np.zeros((data.shape[0],data.shape[1],stride)), data[:,:,:-stride]), axis = 2)\n",
    "    \n",
    "    result_list = [data, d2, d8, d4, d6]\n",
    "    result_notNone = tuple(i for i in result_list if isinstance(i, np.ndarray))\n",
    "    \n",
    "    # observation-wise concat\n",
    "    return np.concatenate(result_notNone, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# example\n",
    "some_digit = X[0]\n",
    "some_digit_image = some_digit.reshape(28, 28)\n",
    "\n",
    "plt.subplot(121); plt.imshow(some_digit_image, cmap=mpl.cm.binary)\n",
    "plt.axis(\"off\")\n",
    "plt.subplot(122); plt.imshow(mnist_shifter(some_digit_image,direction = 8, stride = 5)[1], cmap=mpl.cm.binary)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300000, 28, 28)\n",
      "(300000, 784)\n"
     ]
    }
   ],
   "source": [
    "X_train_shift_2d = mnist_shifter(X_train.reshape(X_train.shape[0], 28, 28))\n",
    "print(X_train_shift_2d.shape)\n",
    "\n",
    "X_train_shift = X_train_shift_2d.reshape(X_train_shift_2d.shape[0],784)\n",
    "print(X_train_shift.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 늘어난 training feature수에 맞게 y를 extend 해준다.\n",
    "y_train_ext = np.concatenate((y_train, y_train, y_train, y_train, y_train), axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "std_scaler = StandardScaler()\n",
    "\n",
    "# shifted data\n",
    "X_train_shift_std = std_scaler.fit_transform(X_train_shift)\n",
    "X_test_std = std_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normal data \n",
    "X_train_std = std_scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "<br/>\n",
    "\n",
    "### candidates\n",
    "---\n",
    "* SGD Classifier (logistic, SVM)\n",
    "* random forest\n",
    "* LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\for_deep\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:573: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\user\\anaconda3\\envs\\for_deep\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:573: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SGDClassifier(loss='log', n_jobs=-1, random_state=42), SGDClassifier(n_jobs=-1, random_state=42), RandomForestClassifier(n_jobs=-1, random_state=42), LGBMClassifier(random_state=42)] \n",
      " ---------------------------\n",
      "[0.8909, 0.8868, 0.8302, 0.9225]\n",
      "[0.8948, 0.8925, 0.9803, 0.9827]\n"
     ]
    }
   ],
   "source": [
    "sgd_log = SGDClassifier(loss = \"log\", random_state = 42, n_jobs = -1)\n",
    "sgd_svm = SGDClassifier(loss = \"hinge\", random_state = 42, n_jobs = -1)\n",
    "rf = RandomForestClassifier(random_state = 42, n_jobs = -1)\n",
    "lgb = LGBMClassifier(random_state = 42, n_jobs = -1)\n",
    "\n",
    "model_list = [sgd_log, sgd_svm, rf, lgb]\n",
    "fure_score = []\n",
    "improved_score = []\n",
    "\n",
    "# fure data\n",
    "for m in model_list:\n",
    "    m.fit(X_train_std, y_train)\n",
    "    pred1 = m.predict(X_test_std)\n",
    "    fure_score.append( accuracy_score(y_test,pred1) )\n",
    "\n",
    "# shifted data\n",
    "for m in model_list:\n",
    "    m.fit(X_train_shift_std, y_train_ext)\n",
    "    pred2 = m.predict(X_test_std)\n",
    "    improved_score.append( accuracy_score(y_test,pred2) )\n",
    "\n",
    "print(model_list,'\\n','---------------------------')\n",
    "print(fure_score)\n",
    "print(improved_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
